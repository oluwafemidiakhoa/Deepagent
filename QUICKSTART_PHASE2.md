# Phase 2 Quick Start Guide

**Get started with Memory Firewalls in 5 minutes!**

---

## Installation & Setup

```bash
# Clone the repository
git clone https://github.com/your-org/deepagent.git
cd deepagent

# Install dependencies
pip install -r requirements.txt

# Run the Phase 2 demo
python examples/phase2_attack_detection_demo.py
```

---

## Basic Usage

### Create a Safe Agent with Phase 2

```python
from deepagent.core.safe_agent import create_safe_agent
from deepagent.safety import SafetyMode

# Create agent with full security (Phase 1 + Phase 2)
agent = create_safe_agent(
    llm_provider="openai",
    safety_mode=SafetyMode.STRICT,
    enable_memory_firewall=True  # Enable Phase 2
)

# Run a task
result = agent.run("Research CRISPR gene editing applications")

# Get security statistics
stats = agent.get_security_stats()
print(f"Attacks detected: {stats['phase2']['attacks_detected']}")
```

---

## Configuration Options

### Safety Modes

```python
from deepagent.safety import SafetyMode

# STRICT: Maximum security, blocks most risks
agent = create_safe_agent(safety_mode=SafetyMode.STRICT)

# BALANCED: Balance security and usability (default)
agent = create_safe_agent(safety_mode=SafetyMode.BALANCED)

# PERMISSIVE: Allow more actions, warn on risks
agent = create_safe_agent(safety_mode=SafetyMode.PERMISSIVE)

# RESEARCH: Maximum flexibility for research
agent = create_safe_agent(safety_mode=SafetyMode.RESEARCH)
```

### Fine-Grained Control

```python
from deepagent.core.safe_agent import SafeAgentConfig

config = SafeAgentConfig(
    llm_provider="openai",
    safety_mode=SafetyMode.STRICT,

    # Phase 1 (Action-Level Safety)
    enable_input_validation=True,
    enable_action_authorization=True,
    enable_approval_workflow=True,
    risk_threshold=0.7,

    # Phase 2 (Memory Firewalls)
    enable_memory_firewall=True,
    enable_attack_detection=True,
    enable_sequence_analysis=True,
    enable_reasoning_monitor=True,
    enable_memory_validation=True,

    # User context
    user_role="researcher",
    user_id="user_123",
    environment="production"
)

agent = SafeDeepAgent(config)
```

---

## What Phase 2 Detects

### 1. Multi-Step Attack Patterns

**6 built-in patterns:**
- Data Exfiltration (Backup ‚Üí Export ‚Üí Delete)
- Privilege Escalation (Read ‚Üí Modify ‚Üí Execute)
- Goal Hijacking (Start Normal ‚Üí Abandon ‚Üí Different)
- Scope Expansion (Single ‚Üí Batch ‚Üí All)
- Reconnaissance (System ‚Üí Network ‚Üí Auth)
- Memory Poisoning (Write False ‚Üí Read ‚Üí Execute)

### 2. Goal Alignment Issues

Detects when agent actions drift from original task:
```python
Original: "Research cancer treatment"
Step 1: search("cancer treatment") ‚úÖ Aligned
Step 2: search("cryptocurrency")   ‚ö†Ô∏è Drifting
Step 3: execute("mine_bitcoin.py")  ‚ùå BLOCKED
```

### 3. Privilege Escalation

Tracks risk trajectory over time:
```python
Step 1: read_user() ‚Üí 10% risk
Step 2: read_users() ‚Üí 30% risk
Step 3: update_role("admin") ‚Üí 70% risk ‚ö†Ô∏è ESCALATION
Step 4: admin_command() ‚Üí 90% risk ‚ùå BLOCKED
```

### 4. Memory Tampering

Cryptographic integrity validation:
```python
Original: {'data': ['item1', 'item2']}
Tampered: {'data': ['item1', 'item2', 'malicious']}
Result: ‚ùå TAMPERING DETECTED (hash mismatch)
```

---

## Security Statistics

### Get Comprehensive Stats

```python
stats = agent.get_security_stats()

# Phase 1 statistics
print(f"Blocked injections: {stats['phase1']['blocked_injections']}")
print(f"Blocked actions: {stats['phase1']['blocked_actions']}")

# Phase 2 statistics
print(f"Attacks detected: {stats['phase2']['attacks_detected']}")
print(f"Drift detections: {stats['phase2']['drift_detections']}")
print(f"Escalations: {stats['phase2']['escalation_detections']}")

# Detailed summaries
if 'sequence_summary' in stats['phase2']:
    seq = stats['phase2']['sequence_summary']
    print(f"Total actions: {seq['total_actions']}")
    print(f"Alignment: {seq['alignment']['is_aligned']}")
    print(f"Drift score: {seq['alignment']['drift_score']:.0%}")
```

---

## Real-World Examples

### Example 1: Secure Research Agent

```python
# Create research agent with full protection
agent = create_safe_agent(
    safety_mode=SafetyMode.BALANCED,
    user_role="researcher",
    enable_memory_firewall=True
)

# Safe research task
result = agent.run("""
    Search for recent CRISPR research papers,
    summarize key findings,
    and create a research report
""")

# Agent will:
# ‚úÖ Validate input for prompt injection
# ‚úÖ Authorize each action (search, read, write)
# ‚úÖ Monitor for goal drift
# ‚úÖ Detect multi-step attack patterns
# ‚úÖ Validate memory integrity
```

### Example 2: Production Deployment

```python
# Create production agent with strict security
agent = create_safe_agent(
    safety_mode=SafetyMode.STRICT,
    risk_threshold=0.6,  # Lower threshold
    user_role="api_user",
    user_id="user_456",
    environment="production",
    enable_memory_firewall=True
)

# Set approval callback for high-risk actions
def approval_callback(decision):
    # Custom approval logic
    if decision.risk_score.total_score > 0.7:
        return request_human_approval(decision)
    return True

agent.set_approval_callback(approval_callback)

# Execute task with full monitoring
result = agent.run("Analyze user data and generate insights")
```

---

## Testing & Validation

### Run the Demo

```bash
# Run comprehensive Phase 2 demo
python examples/phase2_attack_detection_demo.py

# Expected output:
# ‚úÖ Data exfiltration attack detected
# ‚úÖ Privilege escalation detected
# ‚úÖ Goal drift detected
# ‚úÖ Memory tampering detected
# ‚úÖ 6 attack patterns loaded
# ‚úÖ Multi-layer security configured
```

### Run All Tests

```bash
# Run Phase 1 tests
python test_phase1_safety.py

# Run Phase 2 tests
python test_attack_patterns.py
python test_sequence_analyzer.py
python test_reasoning_monitor.py
python test_memory_validator.py

# Expected: 32/35 tests passed (91%)
```

---

## Architecture Overview

### 4-Layer Security

```
USER INPUT
    ‚Üì
Layer 1: Input Validation (Phase 1)
    ‚Üì
Layer 2: Action Authorization (Phase 1)
    ‚Üì
Layer 3: Multi-Step Attack Detection (Phase 2) ‚≠ê
    ‚Üì
Layer 4: Action Recording & Monitoring (Phase 2) ‚≠ê
    ‚Üì
TOOL EXECUTION
```

### Phase 2 Components

```python
agent.attack_detector       # Attack pattern database
agent.sequence_analyzer     # Goal alignment & drift
agent.reasoning_monitor     # Reasoning anomaly detection
agent.memory_validator      # Memory integrity validation
```

---

## Common Use Cases

### 1. Research & Analysis
```python
agent = create_safe_agent(
    safety_mode=SafetyMode.RESEARCH,
    enable_memory_firewall=True
)
# Flexible for research, still protected from attacks
```

### 2. Production API
```python
agent = create_safe_agent(
    safety_mode=SafetyMode.STRICT,
    risk_threshold=0.5,
    enable_memory_firewall=True,
    enable_approval_workflow=True
)
# Maximum security for production
```

### 3. Development/Testing
```python
agent = create_safe_agent(
    safety_mode=SafetyMode.BALANCED,
    environment="development",
    enable_memory_firewall=True
)
# Balanced for development
```

---

## Troubleshooting

### "SecurityViolationError: Multi-step attack detected"

This means Phase 2 detected a malicious pattern:
```python
try:
    result = agent.run(task)
except SecurityViolationError as e:
    print(f"Attack detected: {e.details['pattern_id']}")
    print(f"Confidence: {e.details['confidence']:.0%}")
    # Log and investigate
```

### "UnauthorizedActionError: Action not authorized"

This means Phase 1 blocked a high-risk action:
```python
try:
    result = agent.run(task)
except UnauthorizedActionError as e:
    print(f"Blocked action: {e.action}")
    # Adjust risk threshold or request approval
```

### False Positives

If legitimate workflows are blocked:
```python
# Option 1: Lower risk threshold
config.risk_threshold = 0.8

# Option 2: Use PERMISSIVE mode
config.safety_mode = SafetyMode.PERMISSIVE

# Option 3: Disable specific checks
config.enable_attack_detection = False
```

---

## Performance

- **Input validation**: <10ms overhead
- **Action authorization**: <50ms overhead
- **Attack detection**: <100ms overhead
- **Sequence analysis**: <100ms overhead

**Total overhead**: ~200-300ms per action (acceptable for most use cases)

---

## Next Steps

1. **Try the demo**: `python examples/phase2_attack_detection_demo.py`
2. **Read the docs**: [PHASE2_COMPLETE.md](PHASE2_COMPLETE.md)
3. **Explore patterns**: Check [attack_patterns.py](deepagent/safety/memory_firewall/attack_patterns.py)
4. **Customize**: Adjust config for your use case
5. **Add patterns**: Extend with custom attack patterns

---

## Support

- **Documentation**: See [docs/](docs/) folder
- **Examples**: See [examples/](examples/) folder
- **Tests**: See test files in root directory
- **Issues**: Report at GitHub issues

---

**Phase 2 is production-ready! Start building secure agentic AI today.** üöÄ
